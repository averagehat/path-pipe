Sequencing data were analyzed using a rapid computa-
tional pipeline developed by the DeRisi Laboratory to 
classify MDS reads and identify potential pathogens by 
comparison to the entire NCBI nucleotide reference 
database [6]. The pipeline consists of the following steps.

Diagnosing Balamuthia mandrillaris encephalitis with metagenomic deep sequencing

STAR docs:  https://github.com/alexdobin/STAR/raw/master/doc/STARmanual.pdf
annotations are reccomended (sjdbGTFfile or in mapping step)
hg38 = http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz

pantro4 = http://hgdownload.cse.ucsc.edu/goldenPath/panTro4/bigZips/panTro4.fa.gz

"panTro4.fa" %> \out -> do
  let src = out <.> "gz"
  need [src]
  cmd "gunzip" src

"panTro4.fa.gz" %> \out -> do
  cmd "wget" panTroUrl

downloadRules unpackCmd url = do
  want [unpacked]

  packed %> \out -> do
    cmd "wget" out

  unpacked %> \out -> do
    need [packed] 
    cmd unpackCmd src

where
 packed = reverse $ takeWhile (/= '/') $ reverse url
 unpacked = packed -<.> ""
-- getCmd "gz" = "gunzip"
-- getCmd "tar" = "gunzip"
-- getCmd "zip" = "unzip"


threads options
note: requires more than 30GB ram to index and map.

EXITING because of FATAL PARAMETER ERROR: limitGenomeGenerateRAM=31000000000is too small for your genome
SOLUTION: please specify limitGenomeGenerateRAM not less than34085737173 and make that much RAM available
Indexing:
$ mkdir $indexDir  # requires 100gb 

--runMode genomeGenerate  // says to run genome indices
--runThreadN
--genomeFastaFiles hg38 panTro4
--sjdbOverhang (readLen - 1) -- or 100
--genomeDir indexDir

Mapping:

--runThreadN
--readFilesIn r1.fq r2.fq 
--readFilesCommand gunzip -c / zcat
--genomeDir indexDir
// --outFileNamePrefix outdir/outfile
// --outSAMtype BAM SortedByCoordinate

"Aligned.out.sam"  %> \out -> do
  runStar $ starOpts opts

STAR (v2.5.1b) with:  hg38, (panTro4, 2011, UCSC)
-- drop unaligned reads (using samtools filter flag from pathdiscov)
samtools view paired.bam -f 12 | cut -f1 | sort -u | awk '{print "@"$0}' > paired.unmap.id
pathdiscov/host_map/bwa_filter_host.sh:53   https://github.com/VDBWRAIR/pathdiscov/pull/291/files#diff-8d4a24890c036d1e053b66a51f1ecf19R53
-- will need to restore to fastq format as paired reads. 
duplicate removal
 > samtools rmdup?

PriceSeqFilter [11] with the “-rnf 90” and “-rqf 85 0.98” settings.


./PriceSource140408/PriceSeqFilter -fp $fwd $rev -rnf 90 -rqf 85 0.98 -op $fwd.filtered $rev.filtered
-- output files must match fq extension
["filtered/star-fwd.fq", "filtered/star-rev.fq"] &%> \[fwdO, revO] -> do
  let (fwd, rev) = (basename fwdO, basename revO)
  need [fwd, rev]
  let priceSeqFilter = cmd "PriceSource140408/PriceSeqFilter"
  priceSeqFilter "-fp" fwd rev "-rnf" 90 "-rqf" 85 0.98 "-op" fwdO revO


data PSFopts = PSFopts { calledPercent :: Int <= 100
                       , hiqhQualPercent :: Int <=100
                       , highQualMin :: Float } -- <= 1 


cd-hit-dup (v4.6.1) compress: reads at least 95% identical 

cdhit/cd-hit-auxtools/cd-hit-dup
cd-hit-dup -i R1.fq -i2 R2.fq -o output -o2 output-R2 [other options] (for PE reads FASTQ)

but how to compress? 

 Paired reads were then assessed for complexity by compression with the Lempel-Ziv-Welch algorithm [13]. Read pairs with a compression score <0.45 were subsequently removed.

Bowtie2 (v2.2.4) (very-sensitive-local) with: hg38, panTro4
-- drop all except Read pairs in which both members remained unmapped 
GSNAPL (v2015-12-31) 
 -- NCBI NT (downloaded July 2015, indexed with k = 16mers), and preprocessed to remove known repetitive sequences with RepeatMasker (vOpen-4.0) (www.repeatmasker.org).

Rapsearch2:  NCBI non-redundant protein database (July 2015) 


-- "preprocessed to remove known repetitive sequences with RepeatMasker" -- does this apply to nt/nr database? 
-- NT was in some way de-duped

